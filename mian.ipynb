{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "dependencies </n>\n",
    "Env :: Forecastinit\n",
    "Python=3.11.5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# General \n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# sklearn \n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "# skforecast \n",
    "from skforecast.datasets import load_demo_dataset\n",
    "from skforecast.ForecasterAutoreg import ForecasterAutoreg\n",
    "from skforecast.model_selection import backtesting_forecaster\n",
    "from skforecast.model_selection import grid_search_forecaster\n",
    "\n",
    "# ML Models \n",
    "from xgboost import XGBRegressor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "Historical_data_org = pd.read_csv('Input/Actual.csv')\n",
    "TimeKey_org = pd.read_csv('Input/Time.csv')\n",
    "Forecast_level = ['Version.[Version Name]', 'Channel.[Channel]', 'Account.[Account]',\n",
    "       'PnL.[PnL]', 'Demand Domain.[Demand Domain]', 'Region.[Region]',\n",
    "       'Location.[Location]', 'Time.[Planning Month]', 'Item.[Item]']\n",
    "Time_column = ['Time.[Planning Month]']\n",
    "Historical_data_column = ['Actual']\n",
    "#Date should be in format of time key column, which is available in TimeKey file \n",
    "Time_key_column_name = \"Time.[PlanningMonthKey]\"\n",
    "Time_key_date_format = \"%m/%d/%Y %I:%M:%S %p\"\n",
    "Historic_start_date = \"M09-20\" \n",
    "Historic_end_date = \"M12-22\"\n",
    "Forecast_start_date = \"M01-23\"\n",
    "Forecast_end_date = \"M03-23\"\n",
    "drivers = ['driver_Month']\n",
    "models = [\"Random Forest\", \"XG Boost\"]\n",
    "Hypertunning = False\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lags used in grid search hyper tunning \n",
    "# lags_grid = [2,3,6,[1,2,3],[1,2,3,6],[3,6],[1,2,3,6]]\n",
    "lags_grid = [2,6,[1,2,3]]\n",
    "\n",
    "# parameters used in grid search hyper tunning \n",
    "param_grid = {\n",
    "    'n_estimators': [50, 100, 200, 500, 1000, 1500],\n",
    "    'max_depth': [2, 5, 8, 10, 12, 15]\n",
    "}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Custom Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data filter based on start and end date, then split in X and y based on provided columns \n",
    "# split(historical data frame contains drivers and actual, start date , end date, X columns in list, y column in string )\n",
    "def split(data,Historic_start_date_key,Historic_end_date_key,Forecast_start_date_key,Forecast_end_date_key,X_cols,y_col):\n",
    "    data = data[(data['TimeKey']>=Historic_start_date_key)&(data['TimeKey']<=Forecast_end_date_key)]\n",
    "    data.sort_values('TimeKey',inplace=True)\n",
    "    data.reset_index(drop=True,inplace=True)\n",
    "    \n",
    "    # creating date range this will be only for index related purpose , will not used in forecasting \n",
    "    index = pd.Series(pd.date_range(start=Historic_start_date_key,periods=len(data)))\n",
    "    data['index'] = index\n",
    "    data.set_index('index',inplace=True)\n",
    "    data = data.asfreq('D')\n",
    "\n",
    "    #  train/test \n",
    "    train =  data[(data['TimeKey']>=Historic_start_date_key)&(data['TimeKey']<=Historic_end_date_key)]\n",
    "    test =  data[(data['TimeKey']>Historic_end_date_key)&(data['TimeKey']<=Forecast_end_date_key)]\n",
    "    \n",
    "    \n",
    "    X_train = train[['key','TimeKey']+X_cols]\n",
    "    y_train = train[['TimeKey']+[y_col]]\n",
    "\n",
    "    X_test = test[['key','TimeKey']+X_cols]\n",
    "    y_test = test[['TimeKey']+[y_col]]\n",
    "    return X_train,y_train,X_test,y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fit the model \n",
    "# if Hypertunning is turned on fit will be in grid search else normal fit with default values will return \n",
    "def skforecastgridsrchfit(forecaster,y_train_loc,X_train_loc,drivers_loc,param_grid,lags_grid):\n",
    "    results = grid_search_forecaster(\n",
    "              forecaster         = forecaster,\n",
    "              y                  = y_train_loc,\n",
    "              param_grid         = param_grid,\n",
    "              lags_grid          = lags_grid,\n",
    "              steps              = 12,\n",
    "              refit              = True,\n",
    "              metric             = 'mean_squared_error',\n",
    "              initial_train_size = len(y_train)-1,\n",
    "              fixed_train_size   = False,\n",
    "              return_best        = True,\n",
    "              n_jobs             = 'auto',\n",
    "              verbose            = False,\n",
    "              show_progress      = True,\n",
    "              exog               = X_train_loc[drivers_loc]\n",
    "          )   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SK Forecast ML Models\n",
    "# skforecastpredict(models in list, X train data frame, y train data frame, X test data frame ) \n",
    "def skforecastpredict(models,Historical_data_column, X_train, y_train, X_test, drivers_local, Hypertunning,param_grid,lags_grid):\n",
    "    # Predicted output data frame \n",
    "    Output = pd.DataFrame()\n",
    "    # converting data frame to series, as sk forecast y accept series \n",
    "    y_train_loc = y_train[Historical_data_column[0]]\n",
    "    \n",
    "    # from sklearn.preprocessing import FunctionTransformer\n",
    "    # transformer_y = FunctionTransformer(func=np.log1p, inverse_func=np.expm1)\n",
    "\n",
    "    # Random Forest ========================================================================================================================= \n",
    "    if \"Random Forest\" in models:\n",
    "        randomforestforecaster = ForecasterAutoreg(\n",
    "                 regressor = RandomForestRegressor(random_state=123),\n",
    "                 lags      = [2]\n",
    "             )\n",
    "        if Hypertunning is True:\n",
    "            skforecastgridsrchfit(randomforestforecaster,y_train_loc,X_train,drivers_local,param_grid,lags_grid)\n",
    "        else:\n",
    "            randomforestforecaster.fit(y= y_train_loc, exog=X_train[drivers_local])\n",
    "        y_hat_randomforest = randomforestforecaster.predict_interval(steps=3,exog=X_test[drivers_local]).reset_index(drop=True)\n",
    "        y_hat_randomforest.columns = ['Random Forest Y_hat', 'Random Forest Lower Bound', 'Random Forest Upper Bound']\n",
    "        Output = pd.concat([Output, y_hat_randomforest], axis=1)\n",
    "    # xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx\n",
    "    \n",
    "    #XG Boost ================================================================================================================================\n",
    "    if \"XG Boost\" in models:\n",
    "        xgboostForecaster = ForecasterAutoreg(\n",
    "                regressor= XGBRegressor(random_state = 123),\n",
    "                lags= [1,2]\n",
    "            )      \n",
    "        if Hypertunning is True:\n",
    "            skforecastgridsrchfit(xgboostForecaster,y_train_loc,X_train,drivers_local,param_grid,lags_grid)\n",
    "        else:\n",
    "            xgboostForecaster.fit(y=y_train_loc, exog=X_train[drivers_local])\n",
    "        y_hat_xgboost = xgboostForecaster.predict_interval(steps=3,exog=X_test[drivers]).reset_index(drop=True)\n",
    "        y_hat_xgboost.columns = ['XG Boost Y_hat', 'XG Boost Lower Bound', 'XG Boost Upper Bound']\n",
    "        Output = pd.concat([Output, y_hat_xgboost], axis=1)\n",
    "    # xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx\n",
    "        \n",
    "    return Output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Processing Input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Version.[Version Name]',\n",
       " 'Channel.[Channel]',\n",
       " 'Account.[Account]',\n",
       " 'PnL.[PnL]',\n",
       " 'Demand Domain.[Demand Domain]',\n",
       " 'Region.[Region]',\n",
       " 'Location.[Location]',\n",
       " 'Item.[Item]']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Forecast_level_minus_time = Forecast_level.copy()\n",
    "Forecast_level_minus_time.remove(Time_column[0])\n",
    "Forecast_level_minus_time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Copy Input "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "Historical_data = Historical_data_org.copy(deep=True)\n",
    "TimeKey = TimeKey_org.copy(deep=True)\n",
    "TimeKey['TimeKey'] = pd.to_datetime(TimeKey[Time_key_column_name], format=Time_key_date_format)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculating Historic_end_date_key\n",
    "Historic_start_date_key = pd.to_datetime(TimeKey[TimeKey[Time_column[0]]==Historic_start_date]['TimeKey'].values[0])\n",
    "Historic_end_date_key = pd.to_datetime(TimeKey[TimeKey[Time_column[0]]==Historic_end_date]['TimeKey'].values[0])\n",
    "Forecast_start_date_key = pd.to_datetime(TimeKey[TimeKey[Time_column[0]]==Forecast_start_date]['TimeKey'].values[0])\n",
    "Forecast_end_date_key = pd.to_datetime(TimeKey[TimeKey[Time_column[0]]==Forecast_end_date]['TimeKey'].values[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Processing Copy Input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "Historical_data[Historical_data_column] = Historical_data[Historical_data_column].astype(float)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creating Key in Historical Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Time.[Planning Month]</th>\n",
       "      <th>Actual</th>\n",
       "      <th>key</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>M07-20</td>\n",
       "      <td>445.0</td>\n",
       "      <td>CurrentWorkingView__ MDJoinner__B2B__ MDJoinne...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>M08-20</td>\n",
       "      <td>711.0</td>\n",
       "      <td>CurrentWorkingView__ MDJoinner__B2B__ MDJoinne...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Time.[Planning Month]  Actual  \\\n",
       "0                M07-20   445.0   \n",
       "1                M08-20   711.0   \n",
       "\n",
       "                                                 key  \n",
       "0  CurrentWorkingView__ MDJoinner__B2B__ MDJoinne...  \n",
       "1  CurrentWorkingView__ MDJoinner__B2B__ MDJoinne...  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# creating keys \n",
    "Historical_data['key'] = Historical_data[Forecast_level_minus_time].astype(str).agg(\"__ MDJoinner__\".join, axis=1)\n",
    "# dropping columns, which is already present in keys \n",
    "Historical_data.drop(Forecast_level_minus_time,axis=1,inplace=True) \n",
    "Historical_data.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Custom Filter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "Historical_data = Historical_data[Historical_data['key']=='CurrentWorkingView__ MDJoinner__B2B__ MDJoinner__AMO__ MDJoinner__DP__ MDJoinner__DP__ MDJoinner__ShipTo1__ MDJoinner__DP__ MDJoinner__Loctite 248 19g Stick']\n",
    "# Historical_data['key'].values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Merging Time Key in Historical Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Time.[Planning Month]</th>\n",
       "      <th>Actual</th>\n",
       "      <th>key</th>\n",
       "      <th>TimeKey</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>M07-20</td>\n",
       "      <td>445.0</td>\n",
       "      <td>CurrentWorkingView__ MDJoinner__B2B__ MDJoinne...</td>\n",
       "      <td>2020-07-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>M08-20</td>\n",
       "      <td>711.0</td>\n",
       "      <td>CurrentWorkingView__ MDJoinner__B2B__ MDJoinne...</td>\n",
       "      <td>2020-08-02</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Time.[Planning Month]  Actual  \\\n",
       "0                M07-20   445.0   \n",
       "1                M08-20   711.0   \n",
       "\n",
       "                                                 key    TimeKey  \n",
       "0  CurrentWorkingView__ MDJoinner__B2B__ MDJoinne... 2020-07-05  \n",
       "1  CurrentWorkingView__ MDJoinner__B2B__ MDJoinne... 2020-08-02  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Historical_data = pd.merge(Historical_data,TimeKey[Time_column+[\"TimeKey\"]],on=Time_column,how='left')\n",
    "Historical_data.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Adding features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Time.[Planning Month]</th>\n",
       "      <th>Actual</th>\n",
       "      <th>key</th>\n",
       "      <th>TimeKey</th>\n",
       "      <th>driver_Month</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>M07-20</td>\n",
       "      <td>445.0</td>\n",
       "      <td>CurrentWorkingView__ MDJoinner__B2B__ MDJoinne...</td>\n",
       "      <td>2020-07-05</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>M08-20</td>\n",
       "      <td>711.0</td>\n",
       "      <td>CurrentWorkingView__ MDJoinner__B2B__ MDJoinne...</td>\n",
       "      <td>2020-08-02</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>M09-20</td>\n",
       "      <td>462.0</td>\n",
       "      <td>CurrentWorkingView__ MDJoinner__B2B__ MDJoinne...</td>\n",
       "      <td>2020-08-30</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>M10-20</td>\n",
       "      <td>174.0</td>\n",
       "      <td>CurrentWorkingView__ MDJoinner__B2B__ MDJoinne...</td>\n",
       "      <td>2020-10-04</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>M11-20</td>\n",
       "      <td>179.0</td>\n",
       "      <td>CurrentWorkingView__ MDJoinner__B2B__ MDJoinne...</td>\n",
       "      <td>2020-11-01</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Time.[Planning Month]  Actual  \\\n",
       "0                M07-20   445.0   \n",
       "1                M08-20   711.0   \n",
       "2                M09-20   462.0   \n",
       "3                M10-20   174.0   \n",
       "4                M11-20   179.0   \n",
       "\n",
       "                                                 key    TimeKey  driver_Month  \n",
       "0  CurrentWorkingView__ MDJoinner__B2B__ MDJoinne... 2020-07-05             7  \n",
       "1  CurrentWorkingView__ MDJoinner__B2B__ MDJoinne... 2020-08-02             8  \n",
       "2  CurrentWorkingView__ MDJoinner__B2B__ MDJoinne... 2020-08-30             8  \n",
       "3  CurrentWorkingView__ MDJoinner__B2B__ MDJoinne... 2020-10-04            10  \n",
       "4  CurrentWorkingView__ MDJoinner__B2B__ MDJoinne... 2020-11-01            11  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Creating drivers \n",
    "Historical_data['driver_Month'] = Historical_data['TimeKey'].dt.month\n",
    "Historical_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train and Test Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1045/4280792445.py:5: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data.sort_values('TimeKey',inplace=True)\n",
      "/tmp/ipykernel_1045/4280792445.py:10: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data['index'] = index\n"
     ]
    }
   ],
   "source": [
    "X_train,y_train,X_test,y_test = split(Historical_data, Historic_start_date_key,Historic_end_date_key,Forecast_start_date_key,Forecast_end_date_key,drivers,Historical_data_column[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of models compared: 108.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c61b33edc7de41a6925246f9018639d3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "lags grid:   0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a42f9d504bba4956b6604649e6ab1438",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "params grid:   0%|          | 0/36 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mEmpty\u001b[0m                                     Traceback (most recent call last)",
      "File \u001b[0;32m~/anaconda3/envs/Forecastinit/lib/python3.11/site-packages/joblib/parallel.py:862\u001b[0m, in \u001b[0;36mParallel.dispatch_one_batch\u001b[0;34m(self, iterator)\u001b[0m\n\u001b[1;32m    861\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 862\u001b[0m     tasks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_ready_batches\u001b[38;5;241m.\u001b[39mget(block\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[1;32m    863\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m queue\u001b[38;5;241m.\u001b[39mEmpty:\n\u001b[1;32m    864\u001b[0m     \u001b[38;5;66;03m# slice the iterator n_jobs * batchsize items at a time. If the\u001b[39;00m\n\u001b[1;32m    865\u001b[0m     \u001b[38;5;66;03m# slice returns less than that, then the current batchsize puts\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    868\u001b[0m     \u001b[38;5;66;03m# accordingly to distribute evenly the last items between all\u001b[39;00m\n\u001b[1;32m    869\u001b[0m     \u001b[38;5;66;03m# workers.\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/Forecastinit/lib/python3.11/queue.py:168\u001b[0m, in \u001b[0;36mQueue.get\u001b[0;34m(self, block, timeout)\u001b[0m\n\u001b[1;32m    167\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_qsize():\n\u001b[0;32m--> 168\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m Empty\n\u001b[1;32m    169\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m timeout \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[0;31mEmpty\u001b[0m: ",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[16], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m Hypertunning\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m      2\u001b[0m models \u001b[38;5;241m=\u001b[39m [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mRandom Forest\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mXG Boost\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[0;32m----> 3\u001b[0m rf \u001b[38;5;241m=\u001b[39m skforecastpredict(models, Historical_data_column, X_train, y_train, X_test, drivers, Hypertunning, param_grid, lags_grid)\n",
      "Cell \u001b[0;32mIn[6], line 19\u001b[0m, in \u001b[0;36mskforecastpredict\u001b[0;34m(models, Historical_data_column, X_train, y_train, X_test, drivers_local, Hypertunning, param_grid, lags_grid)\u001b[0m\n\u001b[1;32m     14\u001b[0m randomforestforecaster \u001b[38;5;241m=\u001b[39m ForecasterAutoreg(\n\u001b[1;32m     15\u001b[0m          regressor \u001b[38;5;241m=\u001b[39m RandomForestRegressor(random_state\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m123\u001b[39m),\n\u001b[1;32m     16\u001b[0m          lags      \u001b[38;5;241m=\u001b[39m [\u001b[38;5;241m2\u001b[39m]\n\u001b[1;32m     17\u001b[0m      )\n\u001b[1;32m     18\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m Hypertunning \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[0;32m---> 19\u001b[0m     skforecastgridsrchfit(randomforestforecaster,y_train_loc,X_train,drivers_local,param_grid,lags_grid)\n\u001b[1;32m     20\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     21\u001b[0m     randomforestforecaster\u001b[38;5;241m.\u001b[39mfit(y\u001b[38;5;241m=\u001b[39m y_train_loc, exog\u001b[38;5;241m=\u001b[39mX_train[drivers_local])\n",
      "Cell \u001b[0;32mIn[5], line 4\u001b[0m, in \u001b[0;36mskforecastgridsrchfit\u001b[0;34m(forecaster, y_train_loc, X_train_loc, drivers_loc, param_grid, lags_grid)\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mskforecastgridsrchfit\u001b[39m(forecaster,y_train_loc,X_train_loc,drivers_loc,param_grid,lags_grid):\n\u001b[0;32m----> 4\u001b[0m     results \u001b[38;5;241m=\u001b[39m grid_search_forecaster(\n\u001b[1;32m      5\u001b[0m               forecaster         \u001b[38;5;241m=\u001b[39m forecaster,\n\u001b[1;32m      6\u001b[0m               y                  \u001b[38;5;241m=\u001b[39m y_train_loc,\n\u001b[1;32m      7\u001b[0m               param_grid         \u001b[38;5;241m=\u001b[39m param_grid,\n\u001b[1;32m      8\u001b[0m               lags_grid          \u001b[38;5;241m=\u001b[39m lags_grid,\n\u001b[1;32m      9\u001b[0m               steps              \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m12\u001b[39m,\n\u001b[1;32m     10\u001b[0m               refit              \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[1;32m     11\u001b[0m               metric             \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmean_squared_error\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[1;32m     12\u001b[0m               initial_train_size \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(y_train)\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m,\n\u001b[1;32m     13\u001b[0m               fixed_train_size   \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[1;32m     14\u001b[0m               return_best        \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[1;32m     15\u001b[0m               n_jobs             \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mauto\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[1;32m     16\u001b[0m               verbose            \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[1;32m     17\u001b[0m               show_progress      \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[1;32m     18\u001b[0m               exog               \u001b[38;5;241m=\u001b[39m X_train_loc[drivers_loc]\n\u001b[1;32m     19\u001b[0m           )\n",
      "File \u001b[0;32m~/anaconda3/envs/Forecastinit/lib/python3.11/site-packages/skforecast/model_selection/model_selection.py:911\u001b[0m, in \u001b[0;36mgrid_search_forecaster\u001b[0;34m(forecaster, y, param_grid, steps, metric, initial_train_size, fixed_train_size, gap, allow_incomplete_fold, exog, lags_grid, refit, return_best, n_jobs, verbose, show_progress)\u001b[0m\n\u001b[1;32m    842\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    843\u001b[0m \u001b[38;5;124;03mExhaustive search over specified parameter values for a Forecaster object.\u001b[39;00m\n\u001b[1;32m    844\u001b[0m \u001b[38;5;124;03mValidation is done using time series backtesting.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    906\u001b[0m \u001b[38;5;124;03m\u001b[39;00m\n\u001b[1;32m    907\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    909\u001b[0m param_grid \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(ParameterGrid(param_grid))\n\u001b[0;32m--> 911\u001b[0m results \u001b[38;5;241m=\u001b[39m _evaluate_grid_hyperparameters(\n\u001b[1;32m    912\u001b[0m     forecaster            \u001b[38;5;241m=\u001b[39m forecaster,\n\u001b[1;32m    913\u001b[0m     y                     \u001b[38;5;241m=\u001b[39m y,\n\u001b[1;32m    914\u001b[0m     param_grid            \u001b[38;5;241m=\u001b[39m param_grid,\n\u001b[1;32m    915\u001b[0m     steps                 \u001b[38;5;241m=\u001b[39m steps,\n\u001b[1;32m    916\u001b[0m     metric                \u001b[38;5;241m=\u001b[39m metric,\n\u001b[1;32m    917\u001b[0m     initial_train_size    \u001b[38;5;241m=\u001b[39m initial_train_size,\n\u001b[1;32m    918\u001b[0m     fixed_train_size      \u001b[38;5;241m=\u001b[39m fixed_train_size,\n\u001b[1;32m    919\u001b[0m     gap                   \u001b[38;5;241m=\u001b[39m gap,\n\u001b[1;32m    920\u001b[0m     allow_incomplete_fold \u001b[38;5;241m=\u001b[39m allow_incomplete_fold,\n\u001b[1;32m    921\u001b[0m     exog                  \u001b[38;5;241m=\u001b[39m exog,\n\u001b[1;32m    922\u001b[0m     lags_grid             \u001b[38;5;241m=\u001b[39m lags_grid,\n\u001b[1;32m    923\u001b[0m     refit                 \u001b[38;5;241m=\u001b[39m refit,\n\u001b[1;32m    924\u001b[0m     return_best           \u001b[38;5;241m=\u001b[39m return_best,\n\u001b[1;32m    925\u001b[0m     n_jobs                \u001b[38;5;241m=\u001b[39m n_jobs,\n\u001b[1;32m    926\u001b[0m     verbose               \u001b[38;5;241m=\u001b[39m verbose,\n\u001b[1;32m    927\u001b[0m     show_progress         \u001b[38;5;241m=\u001b[39m show_progress\n\u001b[1;32m    928\u001b[0m )\n\u001b[1;32m    930\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m results\n",
      "File \u001b[0;32m~/anaconda3/envs/Forecastinit/lib/python3.11/site-packages/skforecast/model_selection/model_selection.py:1176\u001b[0m, in \u001b[0;36m_evaluate_grid_hyperparameters\u001b[0;34m(forecaster, y, param_grid, steps, metric, initial_train_size, fixed_train_size, gap, allow_incomplete_fold, exog, lags_grid, refit, return_best, n_jobs, verbose, show_progress)\u001b[0m\n\u001b[1;32m   1173\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m params \u001b[38;5;129;01min\u001b[39;00m param_grid:\n\u001b[1;32m   1175\u001b[0m     forecaster\u001b[38;5;241m.\u001b[39mset_params(params)\n\u001b[0;32m-> 1176\u001b[0m     metrics_values \u001b[38;5;241m=\u001b[39m backtesting_forecaster(\n\u001b[1;32m   1177\u001b[0m                          forecaster            \u001b[38;5;241m=\u001b[39m forecaster,\n\u001b[1;32m   1178\u001b[0m                          y                     \u001b[38;5;241m=\u001b[39m y,\n\u001b[1;32m   1179\u001b[0m                          steps                 \u001b[38;5;241m=\u001b[39m steps,\n\u001b[1;32m   1180\u001b[0m                          metric                \u001b[38;5;241m=\u001b[39m metric,\n\u001b[1;32m   1181\u001b[0m                          initial_train_size    \u001b[38;5;241m=\u001b[39m initial_train_size,\n\u001b[1;32m   1182\u001b[0m                          fixed_train_size      \u001b[38;5;241m=\u001b[39m fixed_train_size,\n\u001b[1;32m   1183\u001b[0m                          gap                   \u001b[38;5;241m=\u001b[39m gap,\n\u001b[1;32m   1184\u001b[0m                          allow_incomplete_fold \u001b[38;5;241m=\u001b[39m allow_incomplete_fold,\n\u001b[1;32m   1185\u001b[0m                          exog                  \u001b[38;5;241m=\u001b[39m exog,\n\u001b[1;32m   1186\u001b[0m                          refit                 \u001b[38;5;241m=\u001b[39m refit,\n\u001b[1;32m   1187\u001b[0m                          interval              \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m   1188\u001b[0m                          n_jobs                \u001b[38;5;241m=\u001b[39m n_jobs,\n\u001b[1;32m   1189\u001b[0m                          verbose               \u001b[38;5;241m=\u001b[39m verbose,\n\u001b[1;32m   1190\u001b[0m                          show_progress         \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[1;32m   1191\u001b[0m                      )[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m   1192\u001b[0m     warnings\u001b[38;5;241m.\u001b[39mfilterwarnings(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mignore\u001b[39m\u001b[38;5;124m'\u001b[39m, category\u001b[38;5;241m=\u001b[39m\u001b[38;5;167;01mRuntimeWarning\u001b[39;00m, message\u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThe forecaster will be fit.*\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m   1193\u001b[0m     lags_list\u001b[38;5;241m.\u001b[39mappend(lags)\n",
      "File \u001b[0;32m~/anaconda3/envs/Forecastinit/lib/python3.11/site-packages/skforecast/model_selection/model_selection.py:801\u001b[0m, in \u001b[0;36mbacktesting_forecaster\u001b[0;34m(forecaster, y, steps, metric, initial_train_size, fixed_train_size, gap, allow_incomplete_fold, exog, refit, interval, n_boot, random_state, in_sample_residuals, n_jobs, verbose, show_progress)\u001b[0m\n\u001b[1;32m    793\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mtype\u001b[39m(forecaster)\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mForecasterAutoregDirect\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[1;32m    794\u001b[0m    forecaster\u001b[38;5;241m.\u001b[39msteps \u001b[38;5;241m<\u001b[39m steps \u001b[38;5;241m+\u001b[39m gap:\n\u001b[1;32m    795\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    796\u001b[0m         (\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mWhen using a ForecasterAutoregDirect, the combination of steps \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    797\u001b[0m          \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m+ gap (\u001b[39m\u001b[38;5;132;01m{\u001b[39;00msteps\u001b[38;5;241m+\u001b[39mgap\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m) cannot be greater than the `steps` parameter \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    798\u001b[0m          \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdeclared when the forecaster is initialized (\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mforecaster\u001b[38;5;241m.\u001b[39msteps\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m).\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    799\u001b[0m     )\n\u001b[0;32m--> 801\u001b[0m metrics_values, backtest_predictions \u001b[38;5;241m=\u001b[39m _backtesting_forecaster(\n\u001b[1;32m    802\u001b[0m     forecaster            \u001b[38;5;241m=\u001b[39m forecaster,\n\u001b[1;32m    803\u001b[0m     y                     \u001b[38;5;241m=\u001b[39m y,\n\u001b[1;32m    804\u001b[0m     steps                 \u001b[38;5;241m=\u001b[39m steps,\n\u001b[1;32m    805\u001b[0m     metric                \u001b[38;5;241m=\u001b[39m metric,\n\u001b[1;32m    806\u001b[0m     initial_train_size    \u001b[38;5;241m=\u001b[39m initial_train_size,\n\u001b[1;32m    807\u001b[0m     fixed_train_size      \u001b[38;5;241m=\u001b[39m fixed_train_size,\n\u001b[1;32m    808\u001b[0m     gap                   \u001b[38;5;241m=\u001b[39m gap,\n\u001b[1;32m    809\u001b[0m     allow_incomplete_fold \u001b[38;5;241m=\u001b[39m allow_incomplete_fold,\n\u001b[1;32m    810\u001b[0m     exog                  \u001b[38;5;241m=\u001b[39m exog,\n\u001b[1;32m    811\u001b[0m     refit                 \u001b[38;5;241m=\u001b[39m refit,\n\u001b[1;32m    812\u001b[0m     interval              \u001b[38;5;241m=\u001b[39m interval,\n\u001b[1;32m    813\u001b[0m     n_boot                \u001b[38;5;241m=\u001b[39m n_boot,\n\u001b[1;32m    814\u001b[0m     random_state          \u001b[38;5;241m=\u001b[39m random_state,\n\u001b[1;32m    815\u001b[0m     in_sample_residuals   \u001b[38;5;241m=\u001b[39m in_sample_residuals,\n\u001b[1;32m    816\u001b[0m     n_jobs                \u001b[38;5;241m=\u001b[39m n_jobs,\n\u001b[1;32m    817\u001b[0m     verbose               \u001b[38;5;241m=\u001b[39m verbose,\n\u001b[1;32m    818\u001b[0m     show_progress         \u001b[38;5;241m=\u001b[39m show_progress\n\u001b[1;32m    819\u001b[0m )\n\u001b[1;32m    821\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m metrics_values, backtest_predictions\n",
      "File \u001b[0;32m~/anaconda3/envs/Forecastinit/lib/python3.11/site-packages/skforecast/model_selection/model_selection.py:510\u001b[0m, in \u001b[0;36m_backtesting_forecaster\u001b[0;34m(forecaster, y, steps, metric, initial_train_size, fixed_train_size, gap, allow_incomplete_fold, exog, refit, interval, n_boot, random_state, in_sample_residuals, n_jobs, verbose, show_progress)\u001b[0m\n\u001b[1;32m    506\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m initial_train_size \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    507\u001b[0m     \u001b[38;5;66;03m# First model training, this is done to allow parallelization when `refit` \u001b[39;00m\n\u001b[1;32m    508\u001b[0m     \u001b[38;5;66;03m# is `False`. The initial Forecaster fit is outside the auxiliary function.\u001b[39;00m\n\u001b[1;32m    509\u001b[0m     exog_train \u001b[38;5;241m=\u001b[39m exog\u001b[38;5;241m.\u001b[39miloc[:initial_train_size, ] \u001b[38;5;28;01mif\u001b[39;00m exog \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m--> 510\u001b[0m     forecaster\u001b[38;5;241m.\u001b[39mfit(\n\u001b[1;32m    511\u001b[0m         y                         \u001b[38;5;241m=\u001b[39m y\u001b[38;5;241m.\u001b[39miloc[:initial_train_size, ],\n\u001b[1;32m    512\u001b[0m         exog                      \u001b[38;5;241m=\u001b[39m exog_train,\n\u001b[1;32m    513\u001b[0m         store_in_sample_residuals \u001b[38;5;241m=\u001b[39m store_in_sample_residuals\n\u001b[1;32m    514\u001b[0m     )\n\u001b[1;32m    515\u001b[0m     window_size \u001b[38;5;241m=\u001b[39m forecaster\u001b[38;5;241m.\u001b[39mwindow_size\n\u001b[1;32m    516\u001b[0m     externally_fitted \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/Forecastinit/lib/python3.11/site-packages/skforecast/ForecasterAutoreg/ForecasterAutoreg.py:530\u001b[0m, in \u001b[0;36mForecasterAutoreg.fit\u001b[0;34m(self, y, exog, store_in_sample_residuals)\u001b[0m\n\u001b[1;32m    527\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mregressor\u001b[38;5;241m.\u001b[39mfit(X\u001b[38;5;241m=\u001b[39mX_train, y\u001b[38;5;241m=\u001b[39my_train, sample_weight\u001b[38;5;241m=\u001b[39msample_weight,\n\u001b[1;32m    528\u001b[0m                        \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfit_kwargs)\n\u001b[1;32m    529\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 530\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mregressor\u001b[38;5;241m.\u001b[39mfit(X\u001b[38;5;241m=\u001b[39mX_train, y\u001b[38;5;241m=\u001b[39my_train, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfit_kwargs)\n\u001b[1;32m    532\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfitted \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m    533\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfit_date \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mTimestamp\u001b[38;5;241m.\u001b[39mtoday()\u001b[38;5;241m.\u001b[39mstrftime(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m%\u001b[39m\u001b[38;5;124mY-\u001b[39m\u001b[38;5;124m%\u001b[39m\u001b[38;5;124mm-\u001b[39m\u001b[38;5;132;01m%d\u001b[39;00m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m%\u001b[39m\u001b[38;5;124mH:\u001b[39m\u001b[38;5;124m%\u001b[39m\u001b[38;5;124mM:\u001b[39m\u001b[38;5;124m%\u001b[39m\u001b[38;5;124mS\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[0;32m~/anaconda3/envs/Forecastinit/lib/python3.11/site-packages/sklearn/base.py:1151\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[0;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1144\u001b[0m     estimator\u001b[38;5;241m.\u001b[39m_validate_params()\n\u001b[1;32m   1146\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[1;32m   1147\u001b[0m     skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[1;32m   1148\u001b[0m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[1;32m   1149\u001b[0m     )\n\u001b[1;32m   1150\u001b[0m ):\n\u001b[0;32m-> 1151\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m fit_method(estimator, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m~/anaconda3/envs/Forecastinit/lib/python3.11/site-packages/sklearn/ensemble/_forest.py:456\u001b[0m, in \u001b[0;36mBaseForest.fit\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m    445\u001b[0m trees \u001b[38;5;241m=\u001b[39m [\n\u001b[1;32m    446\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_make_estimator(append\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m, random_state\u001b[38;5;241m=\u001b[39mrandom_state)\n\u001b[1;32m    447\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(n_more_estimators)\n\u001b[1;32m    448\u001b[0m ]\n\u001b[1;32m    450\u001b[0m \u001b[38;5;66;03m# Parallel loop: we prefer the threading backend as the Cython code\u001b[39;00m\n\u001b[1;32m    451\u001b[0m \u001b[38;5;66;03m# for fitting the trees is internally releasing the Python GIL\u001b[39;00m\n\u001b[1;32m    452\u001b[0m \u001b[38;5;66;03m# making threading more efficient than multiprocessing in\u001b[39;00m\n\u001b[1;32m    453\u001b[0m \u001b[38;5;66;03m# that case. However, for joblib 0.12+ we respect any\u001b[39;00m\n\u001b[1;32m    454\u001b[0m \u001b[38;5;66;03m# parallel_backend contexts set at a higher level,\u001b[39;00m\n\u001b[1;32m    455\u001b[0m \u001b[38;5;66;03m# since correctness does not rely on using threads.\u001b[39;00m\n\u001b[0;32m--> 456\u001b[0m trees \u001b[38;5;241m=\u001b[39m Parallel(\n\u001b[1;32m    457\u001b[0m     n_jobs\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_jobs,\n\u001b[1;32m    458\u001b[0m     verbose\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mverbose,\n\u001b[1;32m    459\u001b[0m     prefer\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mthreads\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    460\u001b[0m )(\n\u001b[1;32m    461\u001b[0m     delayed(_parallel_build_trees)(\n\u001b[1;32m    462\u001b[0m         t,\n\u001b[1;32m    463\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbootstrap,\n\u001b[1;32m    464\u001b[0m         X,\n\u001b[1;32m    465\u001b[0m         y,\n\u001b[1;32m    466\u001b[0m         sample_weight,\n\u001b[1;32m    467\u001b[0m         i,\n\u001b[1;32m    468\u001b[0m         \u001b[38;5;28mlen\u001b[39m(trees),\n\u001b[1;32m    469\u001b[0m         verbose\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mverbose,\n\u001b[1;32m    470\u001b[0m         class_weight\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclass_weight,\n\u001b[1;32m    471\u001b[0m         n_samples_bootstrap\u001b[38;5;241m=\u001b[39mn_samples_bootstrap,\n\u001b[1;32m    472\u001b[0m     )\n\u001b[1;32m    473\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m i, t \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(trees)\n\u001b[1;32m    474\u001b[0m )\n\u001b[1;32m    476\u001b[0m \u001b[38;5;66;03m# Collect newly grown trees\u001b[39;00m\n\u001b[1;32m    477\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mestimators_\u001b[38;5;241m.\u001b[39mextend(trees)\n",
      "File \u001b[0;32m~/anaconda3/envs/Forecastinit/lib/python3.11/site-packages/sklearn/utils/parallel.py:65\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m     60\u001b[0m config \u001b[38;5;241m=\u001b[39m get_config()\n\u001b[1;32m     61\u001b[0m iterable_with_config \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m     62\u001b[0m     (_with_config(delayed_func, config), args, kwargs)\n\u001b[1;32m     63\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m delayed_func, args, kwargs \u001b[38;5;129;01min\u001b[39;00m iterable\n\u001b[1;32m     64\u001b[0m )\n\u001b[0;32m---> 65\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__call__\u001b[39m(iterable_with_config)\n",
      "File \u001b[0;32m~/anaconda3/envs/Forecastinit/lib/python3.11/site-packages/joblib/parallel.py:1088\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   1085\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdispatch_one_batch(iterator):\n\u001b[1;32m   1086\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_iterating \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_original_iterator \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m-> 1088\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdispatch_one_batch(iterator):\n\u001b[1;32m   1089\u001b[0m     \u001b[38;5;28;01mpass\u001b[39;00m\n\u001b[1;32m   1091\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m pre_dispatch \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mall\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mor\u001b[39;00m n_jobs \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m   1092\u001b[0m     \u001b[38;5;66;03m# The iterable was consumed all at once by the above for loop.\u001b[39;00m\n\u001b[1;32m   1093\u001b[0m     \u001b[38;5;66;03m# No need to wait for async callbacks to trigger to\u001b[39;00m\n\u001b[1;32m   1094\u001b[0m     \u001b[38;5;66;03m# consumption.\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/Forecastinit/lib/python3.11/site-packages/joblib/parallel.py:890\u001b[0m, in \u001b[0;36mParallel.dispatch_one_batch\u001b[0;34m(self, iterator)\u001b[0m\n\u001b[1;32m    887\u001b[0m \u001b[38;5;66;03m# enqueue n_jobs batches in a local queue\u001b[39;00m\n\u001b[1;32m    888\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m0\u001b[39m, \u001b[38;5;28mlen\u001b[39m(islice), final_batch_size):\n\u001b[1;32m    889\u001b[0m     tasks \u001b[38;5;241m=\u001b[39m BatchedCalls(islice[i:i \u001b[38;5;241m+\u001b[39m final_batch_size],\n\u001b[0;32m--> 890\u001b[0m                          \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backend\u001b[38;5;241m.\u001b[39mget_nested_backend(),\n\u001b[1;32m    891\u001b[0m                          \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reducer_callback,\n\u001b[1;32m    892\u001b[0m                          \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pickle_cache)\n\u001b[1;32m    893\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_ready_batches\u001b[38;5;241m.\u001b[39mput(tasks)\n\u001b[1;32m    895\u001b[0m \u001b[38;5;66;03m# finally, get one task.\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/Forecastinit/lib/python3.11/site-packages/joblib/_parallel_backends.py:219\u001b[0m, in \u001b[0;36mSequentialBackend.get_nested_backend\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    215\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mparallel\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m get_active_backend\n\u001b[1;32m    217\u001b[0m \u001b[38;5;66;03m# SequentialBackend should neither change the nesting level, the\u001b[39;00m\n\u001b[1;32m    218\u001b[0m \u001b[38;5;66;03m# default backend or the number of jobs. Just return the current one.\u001b[39;00m\n\u001b[0;32m--> 219\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m get_active_backend()\n",
      "File \u001b[0;32m~/anaconda3/envs/Forecastinit/lib/python3.11/site-packages/joblib/parallel.py:124\u001b[0m, in \u001b[0;36mget_active_backend\u001b[0;34m(prefer, require, verbose)\u001b[0m\n\u001b[1;32m    120\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m backend_and_jobs\n\u001b[1;32m    122\u001b[0m \u001b[38;5;66;03m# We are outside of the scope of any parallel_backend context manager,\u001b[39;00m\n\u001b[1;32m    123\u001b[0m \u001b[38;5;66;03m# create the default backend instance now.\u001b[39;00m\n\u001b[0;32m--> 124\u001b[0m backend \u001b[38;5;241m=\u001b[39m BACKENDS[DEFAULT_BACKEND](nesting_level\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)\n\u001b[1;32m    125\u001b[0m supports_sharedmem \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mgetattr\u001b[39m(backend, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124msupports_sharedmem\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[1;32m    126\u001b[0m uses_threads \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mgetattr\u001b[39m(backend, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124muses_threads\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "File \u001b[0;32m~/anaconda3/envs/Forecastinit/lib/python3.11/site-packages/joblib/_parallel_backends.py:281\u001b[0m, in \u001b[0;36mAutoBatchingMixin.__init__\u001b[0;34m(self, **kwargs)\u001b[0m\n\u001b[1;32m    280\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m--> 281\u001b[0m     \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    282\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_effective_batch_size \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_DEFAULT_EFFECTIVE_BATCH_SIZE\n\u001b[1;32m    283\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_smoothed_batch_duration \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_DEFAULT_SMOOTHED_BATCH_DURATION\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "Hypertunning=True\n",
    "models = [\"Random Forest\", \"XG Boost\"]\n",
    "rf = skforecastpredict(models, Historical_data_column, X_train, y_train, X_test, drivers, Hypertunning, param_grid, lags_grid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Random Forest Y_hat</th>\n",
       "      <th>Random Forest Lower Bound</th>\n",
       "      <th>Random Forest Upper Bound</th>\n",
       "      <th>XG Boost Y_hat</th>\n",
       "      <th>XG Boost Lower Bound</th>\n",
       "      <th>XG Boost Upper Bound</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>220.22</td>\n",
       "      <td>185.4680</td>\n",
       "      <td>290.060</td>\n",
       "      <td>286.099701</td>\n",
       "      <td>286.098434</td>\n",
       "      <td>286.100861</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>198.05</td>\n",
       "      <td>163.6200</td>\n",
       "      <td>267.890</td>\n",
       "      <td>211.592102</td>\n",
       "      <td>211.590836</td>\n",
       "      <td>211.593262</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>207.58</td>\n",
       "      <td>169.7375</td>\n",
       "      <td>321.936</td>\n",
       "      <td>178.813751</td>\n",
       "      <td>178.812485</td>\n",
       "      <td>178.814911</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Random Forest Y_hat  Random Forest Lower Bound  Random Forest Upper Bound  \\\n",
       "0               220.22                   185.4680                    290.060   \n",
       "1               198.05                   163.6200                    267.890   \n",
       "2               207.58                   169.7375                    321.936   \n",
       "\n",
       "   XG Boost Y_hat  XG Boost Lower Bound  XG Boost Upper Bound  \n",
       "0      286.099701            286.098434            286.100861  \n",
       "1      211.592102            211.590836            211.593262  \n",
       "2      178.813751            178.812485            178.814911  "
      ]
     },
     "execution_count": 157,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pred</th>\n",
       "      <th>lower_bound</th>\n",
       "      <th>upper_bound</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2020-09-27</th>\n",
       "      <td>245.67</td>\n",
       "      <td>173.0600</td>\n",
       "      <td>374.140</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-09-28</th>\n",
       "      <td>236.78</td>\n",
       "      <td>150.8115</td>\n",
       "      <td>390.203</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-09-29</th>\n",
       "      <td>235.31</td>\n",
       "      <td>152.7535</td>\n",
       "      <td>463.226</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              pred  lower_bound  upper_bound\n",
       "2020-09-27  245.67     173.0600      374.140\n",
       "2020-09-28  236.78     150.8115      390.203\n",
       "2020-09-29  235.31     152.7535      463.226"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Grid search hyperparameters and lags\n",
    "# ==============================================================================\n",
    "forecaster = ForecasterAutoreg(\n",
    "                 regressor = RandomForestRegressor(random_state=123),\n",
    "                 lags      = 2 # Placeholder, the value will be overwritten\n",
    "             )\n",
    "\n",
    "# Lags used as predictors\n",
    "lags_grid = [2,3,6,[1,2,3],[1,2,3,6],[3,6],[1,2,3,6]]\n",
    "\n",
    "lags_grid = [2,3]\n",
    "# Regressor hyperparameters\n",
    "param_grid = {\n",
    "    'n_estimators': [50, 100, 200, 500, 1000, 1500],\n",
    "    'max_depth': [2, 5, 8, 10, 12, 15]\n",
    "}\n",
    "\n",
    "forecaster.fit(y=y_train[Historical_data_column[0]],exog=X_train[drivers])\n",
    "forecaster.predict_interval(steps=3,exog=X_test[drivers])\n",
    "# lags_grid = [2, 10, [1, 2, 3, 20]]\n",
    "\n",
    "# Regressor hyperparameters\n",
    "# param_grid = {\n",
    "#     'n_estimators': [50, 100],\n",
    "#     'max_depth': [5, 10, 15]\n",
    "# }\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pred</th>\n",
       "      <th>Random Forest Lower Bound</th>\n",
       "      <th>Random Forest Upper Bound</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>242.18</td>\n",
       "      <td>171.91925</td>\n",
       "      <td>416.8000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>275.09</td>\n",
       "      <td>206.50500</td>\n",
       "      <td>449.7100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>261.68</td>\n",
       "      <td>120.64050</td>\n",
       "      <td>566.3995</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     pred  Random Forest Lower Bound  Random Forest Upper Bound\n",
       "0  242.18                  171.91925                   416.8000\n",
       "1  275.09                  206.50500                   449.7100\n",
       "2  261.68                  120.64050                   566.3995"
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf\n",
    "yhat = rf.rename(columns={'Random Forest Y_hat':'pred','XG Boost Y_hat':'pred'})\n",
    "\n",
    "yhat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>TimeKey</th>\n",
       "      <th>Actual</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2023-01-01</td>\n",
       "      <td>209.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2023-01-29</td>\n",
       "      <td>223.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2023-02-26</td>\n",
       "      <td>333.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     TimeKey  Actual\n",
       "0 2023-01-01   209.0\n",
       "1 2023-01-29   223.0\n",
       "2 2023-02-26   333.0"
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test.reset_index(inplace=True,drop=True)\n",
    "y_test\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pred</th>\n",
       "      <th>TimeKey</th>\n",
       "      <th>Actual</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>242.18</td>\n",
       "      <td>2023-01-01</td>\n",
       "      <td>209.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>275.09</td>\n",
       "      <td>2023-01-29</td>\n",
       "      <td>223.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>261.68</td>\n",
       "      <td>2023-02-26</td>\n",
       "      <td>333.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     pred    TimeKey  Actual\n",
       "0  242.18 2023-01-01   209.0\n",
       "1  275.09 2023-01-29   223.0\n",
       "2  261.68 2023-02-26   333.0"
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "yhat = pd.merge(yhat[['pred']],y_test,left_index=True,right_index=True,how='outer')\n",
    "yhat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>at</th>\n",
       "      <th>diff</th>\n",
       "      <th>Actual</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>all</td>\n",
       "      <td>156.59</td>\n",
       "      <td>765.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    at    diff  Actual\n",
       "0  all  156.59   765.0"
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "yhat['at'] = 'all'\n",
    "yhat['diff'] = abs(yhat['pred'] - yhat['Actual'])\n",
    "yhat = yhat.groupby(['at'],as_index=False)[['diff','Actual']].sum()\n",
    "yhat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy 0    79.530719\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "print(\"Accuracy\",100-yhat['diff']/yhat['Actual']*100)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Henkel",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
